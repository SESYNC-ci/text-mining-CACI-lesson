---
---

## Scraping

![Text](https://imgs.xkcd.com/comics/regular_expressions.png "Wait, forgot to escape a space. Wheeeeee[taptaptap]eeeeee.")  
*by Randall Munroe / [CC BY-NC](http://xkcd.com/license.html)*
{:.captioned}

===

RegEx is a very flexible, and very fast, program for parsing text.

| Pattern      | String with <span style="color:red;">match</span>                                    |
|--------------+--------------------------------------------------------------------------------------|
| Subject:.\*  | <span style="color:red;">Subject: Re: TPS Reports</span>                             |
| \\$[0-9,]+   | The ransom of <span style="color:red;">$1,000,000</span> to Dr. Evil.                |
| \b\S+@\S+\b  | E-mail <span style="color:red;">info@sesync.org</span> or tweet @SESYNC for details! |

Note that "\\" must be escaped in R, so the first pattern would be scripted as `"\\$[0-9,]+"`.

===

Continuing with the Enron e-mails theme, begin by bringing the documents into an analysis with the **tm** package.

```{r, message=FALSE, handout = 0}
library(tm)
library(SnowballC)

docs <- VCorpus(DirSource("data/enron"))
```

```{r}
meta(docs[[1]])
```

===

```{r}
content(docs[[1]])
```

===

The regex pattern `^From: .*` matches any whole line that begins with "From: ". Parentheses cause parts of the match to be captured for substitution or extraction.

```{r, handout = 0}
library(stringr)

txt <- content(docs[[1]])[1:16]
str_match(txt, '^From: (.*)')
```

===

## Extract structured data

The `meta` object for each e-mail was sparsely populated, but some of those variables can be extracted from the `content`.

```{r, handout = 0}
for (i in seq(docs)) {
  txt <- content(docs[[i]])
  match <- str_match(txt, '^From: (.*)')
  row <- !is.na(match[ , 1])
  from <- match[row, 2]
  meta(docs[[i]], "author") <- from[[1]]
}
```

```{r}
meta(docs[[1]])
```
